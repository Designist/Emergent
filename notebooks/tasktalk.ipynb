{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task & Talk\n",
    "Full reimplementation of the task in [Kottur, et al. (2017)](https://arxiv.org/pdf/1706.08502.pdf). Using tabular Q-learning for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Housekeeping\n",
    "Set parameters, initialize the Q-tables, and describe any helper functions we might need for post-analysis.\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 500000\n",
    "eta = 0.8\n",
    "gamma = 0.95\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.0001;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vocab = 3\n",
    "a_vocab = 12\n",
    "\n",
    "num_tasks = 6\n",
    "num_attributes = 4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-State: [att * att, q_vocab, a_vocab+1, q_vocab+1] (+1 for empty vocab)\n",
    "# Q-State (Utterance): [task, q_vocab+1, a_vocab+1] (+1 for empty vocab)\n",
    "# Q-State (Guess): [task, q_vocab, a_vocab, q_vocab, a_vocab]\n",
    "a_table = zeros(num_attributes, num_attributes, num_attributes, q_vocab, a_vocab+1, q_vocab+1, a_vocab)\n",
    "q_table_utt = zeros(num_tasks, q_vocab+1, a_vocab+1, q_vocab)\n",
    "q_table_guess = zeros(num_tasks, q_vocab, a_vocab, q_vocab, a_vocab, num_attributes, num_attributes)\n",
    "\n",
    "a_visited = falses(num_attributes, num_attributes, num_attributes, q_vocab, a_vocab+1, q_vocab+1)\n",
    "q_utt_visited = falses(num_tasks, q_vocab+1, a_vocab+1)\n",
    "q_guess_visited = falses(num_tasks, q_vocab, a_vocab, q_vocab, a_vocab)\n",
    "\n",
    "num_correct = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exploits = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_reward (generic function with 2 methods)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_reward(a_state, guess, num_task)\n",
    "    reward = -1\n",
    "    if (num_task == 1)\n",
    "        if (a_state[1:2] == guess)\n",
    "            reward = 1\n",
    "        end\n",
    "    elseif (num_task == 2)\n",
    "        if (a_state[2:3] == guess)\n",
    "            reward = 1\n",
    "        end\n",
    "    elseif (num_task == 3)\n",
    "        if ([a_state[1], a_state[3]] == guess)\n",
    "            reward = 1\n",
    "        end\n",
    "    elseif (num_task == 4)\n",
    "        if ([a_state[2], a_state[1]] == guess)\n",
    "            reward = 1\n",
    "        end\n",
    "    elseif (num_task == 5)\n",
    "        if ([a_state[3], a_state[2]] == guess)\n",
    "            reward = 1\n",
    "        end\n",
    "    else\n",
    "        if ([a_state[3], a_state[1]] == guess)\n",
    "            reward = 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Return 1 if bool\n",
    "    return reward\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning\n",
    "The core loop of the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9764066142279428\n"
     ]
    }
   ],
   "source": [
    "total_rewards = 0\n",
    "for episode in 1:num_episodes\n",
    "    tradeoff = rand() # exploration-exploitation\n",
    "    explore = (tradeoff < epsilon)\n",
    "    \n",
    "    # Generate random task:\n",
    "    q_state = [rand(1:num_tasks), q_vocab+1, a_vocab+1]\n",
    "    q_states = [copy(q_state)]\n",
    "    \n",
    "    \n",
    "    # Q-BOT\n",
    "    #  -> TURN 1\n",
    "    if explore | ~q_utt_visited[q_state...]\n",
    "        # Explore:\n",
    "        q_state[2] = rand(1:q_vocab)\n",
    "    else\n",
    "        # Exploit:\n",
    "        options = q_table_utt[q_state[1], q_state[2], q_state[3], :]\n",
    "        q_state[2] = argmax(options)\n",
    "    end\n",
    "    \n",
    "    # Generate random object:\n",
    "    a_state = [rand(1:num_attributes), rand(1:num_attributes), rand(1:num_attributes), q_state[2], a_vocab+1, q_vocab+1]\n",
    "    a_states = [copy(a_state)]\n",
    "    \n",
    "    \n",
    "    # A-BOT\n",
    "    #  -> TURN 1\n",
    "    if explore | ~a_visited[a_state...]\n",
    "        # Explore:\n",
    "        a_state[5] = rand(1:a_vocab)\n",
    "    else\n",
    "        # Exploit:\n",
    "        options = a_table[a_state[1], a_state[2], a_state[3], a_state[4], a_state[5], a_state[6], :]\n",
    "        a_state[5] = argmax(options)\n",
    "    end\n",
    "    \n",
    "    q_state[3] = a_state[5]\n",
    "    push!(q_states, copy(q_state))\n",
    "    \n",
    "    \n",
    "    # Q-BOT\n",
    "    #  -> TURN 2\n",
    "    if explore | ~q_utt_visited[q_state...]\n",
    "        # Explore:\n",
    "        a_state[6] = rand(1:q_vocab)\n",
    "    else\n",
    "        # Exploit:\n",
    "        options = q_table_utt[q_state[1], q_state[2], q_state[3], :]\n",
    "        a_state[6] = argmax(options)\n",
    "    end\n",
    "    push!(a_states, copy(a_state))\n",
    "    \n",
    "    # Update Q-State for guessing attributes:\n",
    "    q_state = [q_state[1], q_state[2], q_state[3], a_state[6], a_vocab+1]\n",
    "    \n",
    "    \n",
    "    # A-BOT\n",
    "    #  -> TURN 2\n",
    "    if explore | ~a_visited[a_state...]\n",
    "        # Explore:\n",
    "        q_state[5] = rand(1:a_vocab)\n",
    "    else\n",
    "        # Exploit:\n",
    "        options = a_table[a_state[1], a_state[2], a_state[3], a_state[4], a_state[5], a_state[6], :]\n",
    "        q_state[5] = argmax(options)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    # Q-BOT\n",
    "    #  -> GUESSING PHASE\n",
    "    guess = []\n",
    "    if explore | ~q_guess_visited[q_state...]\n",
    "        # Explore:\n",
    "        guess = [rand(1:num_attributes), rand(1:num_attributes)]\n",
    "    else\n",
    "        # Exploit:\n",
    "        options = q_table_guess[q_state[1], q_state[2], q_state[3], q_state[4], q_state[5], :, :]\n",
    "        optimal_first = num_attributes + 1 # Running best attribute\n",
    "        optimal_second = num_attributes + 1\n",
    "        max_val = -99999\n",
    "        for att1 in 1:num_attributes\n",
    "            for att2 in 1:num_attributes\n",
    "                if (options[att1, att2] > max_val)\n",
    "                    max_val = options[att1, att2]\n",
    "                    optimal_first = att1\n",
    "                    optimal_second = att2\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        guess = [optimal_first, optimal_second]\n",
    "    end\n",
    "    \n",
    "    # Update Reward Tables:\n",
    "    reward = get_reward(a_state, guess, q_state[1])\n",
    "    \n",
    "    a_table[a_state[1],a_state[2],a_state[3],a_state[4],a_vocab+1, q_vocab+1, q_state[3]] += reward\n",
    "    a_visited[a_state[1],a_state[2],a_state[3],a_state[4],a_vocab+1, q_vocab+1] = true\n",
    "    a_table[a_state[1],a_state[2],a_state[3],a_state[4],a_state[5],a_state[6], q_state[5]] += reward\n",
    "    a_visited[a_state[1],a_state[2],a_state[3],a_state[4],a_state[5],a_state[6]] = true\n",
    "    \n",
    "    q_table_utt[q_state[1],q_vocab+1, a_vocab+1, q_state[2]] += reward\n",
    "    q_utt_visited[q_state[1],q_vocab+1, a_vocab+1] = true\n",
    "    q_table_utt[q_state[1],q_state[2],q_state[3], q_state[4]] += reward\n",
    "    q_utt_visited[q_state[1],q_state[2],q_state[3]] = true\n",
    "    \n",
    "    q_table_guess[q_state[1],q_state[2],q_state[3],q_state[4],q_state[5], guess[1], guess[2]] += reward\n",
    "    q_guess_visited[q_state[1],q_state[2],q_state[3],q_state[4],q_state[5]] = true\n",
    "\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*exp(-decay_rate*episode)\n",
    "    \n",
    "#     if (episode % 1000 == 0)\n",
    "#         println(episode, \" | \", epsilon)\n",
    "#     end\n",
    "    \n",
    "    if (~explore) & (episode > 250000)\n",
    "        total_rewards += reward\n",
    "        num_exploits += 1\n",
    "    end\n",
    "end\n",
    "println(\"Accuracy: \", total_rewards/num_exploits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
